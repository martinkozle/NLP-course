{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.metrics import Precision, Recall\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag_sents, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from scripts.word_embeddings import load_embedding_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/MAMI/TRAINING/training.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>Text Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING NEWS: Russia releases photo of DONALD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MAN SEEKING WOMAN Ignad 18 O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Me explaining the deep lore of. J.R.R. Tolkein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WAITING FOR THE END OF THE COVID  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SMART WOMEN ARE AROUND  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>15004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COOKING FOR MY WIFE  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>15006.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0         1.jpg           0        0           0                0         0   \n",
       "1        10.jpg           1        0           0                0         1   \n",
       "2      1000.jpg           0        0           0                0         0   \n",
       "3     10000.jpg           0        0           0                0         0   \n",
       "4     10006.jpg           0        0           0                0         0   \n",
       "...         ...         ...      ...         ...              ...       ...   \n",
       "9995  15002.jpg           0        0           0                0         0   \n",
       "9996  15003.jpg           0        0           0                0         0   \n",
       "9997  15004.jpg           0        0           0                0         0   \n",
       "9998  15005.jpg           0        0           0                0         0   \n",
       "9999  15006.jpg           0        0           0                0         0   \n",
       "\n",
       "                                     Text Transcription  \n",
       "0                                         Milk Milk.zip  \n",
       "1     ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...  \n",
       "2     BREAKING NEWS: Russia releases photo of DONALD...  \n",
       "3                          MAN SEEKING WOMAN Ignad 18 O  \n",
       "4     Me explaining the deep lore of. J.R.R. Tolkein...  \n",
       "...                                                 ...  \n",
       "9995      WAITING FOR THE END OF THE COVID  imgflip.com  \n",
       "9996                SMART WOMEN ARE AROUND  imgflip.com  \n",
       "9997      GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com  \n",
       "9998                   COOKING FOR MY WIFE  imgflip.com  \n",
       "9999  LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get X and y dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Text Transcription']].copy()\n",
    "Y = df[['misogynous', 'shaming', 'stereotype', 'objectification', 'violence']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milk Milk.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING NEWS: Russia releases photo of DONALD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAN SEEKING WOMAN Ignad 18 O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me explaining the deep lore of. J.R.R. Tolkein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>WAITING FOR THE END OF THE COVID  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>SMART WOMEN ARE AROUND  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>COOKING FOR MY WIFE  imgflip.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Text Transcription\n",
       "0                                         Milk Milk.zip\n",
       "1     ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...\n",
       "2     BREAKING NEWS: Russia releases photo of DONALD...\n",
       "3                          MAN SEEKING WOMAN Ignad 18 O\n",
       "4     Me explaining the deep lore of. J.R.R. Tolkein...\n",
       "...                                                 ...\n",
       "9995      WAITING FOR THE END OF THE COVID  imgflip.com\n",
       "9996                SMART WOMEN ARE AROUND  imgflip.com\n",
       "9997      GOOD GIRLS ARE BEHIND THE CORNER  imgflip.com\n",
       "9998                   COOKING FOR MY WIFE  imgflip.com\n",
       "9999  LISTEN TOMORROW WILL BE MONDAY imgflip.com FRO...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      misogynous  shaming  stereotype  objectification  violence\n",
       "0              0        0           0                0         0\n",
       "1              1        0           0                0         1\n",
       "2              0        0           0                0         0\n",
       "3              0        0           0                0         0\n",
       "4              0        0           0                0         0\n",
       "...          ...      ...         ...              ...       ...\n",
       "9995           0        0           0                0         0\n",
       "9996           0        0           0                0         0\n",
       "9997           0        0           0                0         0\n",
       "9998           0        0           0                0         0\n",
       "9999           0        0           0                0         0\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and filter text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_and_word_tokenize_text_series(text_series: pd.Series) -> pd.Series:\n",
    "    return text_series.str.lower().apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = lower_and_word_tokenize_text_series(X['Text Transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        [milk, milk.zip]\n",
       "1       [roses, are, red, ,, violets, are, blue, if, y...\n",
       "2       [breaking, news, :, russia, releases, photo, o...\n",
       "3                     [man, seeking, woman, ignad, 18, o]\n",
       "4       [me, explaining, the, deep, lore, of, ., j.r.r...\n",
       "                              ...                        \n",
       "9995    [waiting, for, the, end, of, the, covid, imgfl...\n",
       "9996             [smart, women, are, around, imgflip.com]\n",
       "9997    [good, girls, are, behind, the, corner, imgfli...\n",
       "9998                [cooking, for, my, wife, imgflip.com]\n",
       "9999    [listen, tomorrow, will, be, monday, imgflip.c...\n",
       "Name: Text Transcription, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords_and_punctuation(tokens_list: pd.Series) -> pd.Series:\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    custom_set = {\n",
    "        '...',\n",
    "        '\"\"',\n",
    "        '``',\n",
    "        \"''\"\n",
    "    }\n",
    "    filter_set = stopset | punctuation | custom_set\n",
    "    \n",
    "    def filter_token(token):\n",
    "        return token not in filter_set and not re.match(r'\\w+\\.(com|net)', token)\n",
    "\n",
    "    return tokens_list.apply(\n",
    "        lambda tokens: list(filter(filter_token, tokens))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = filter_stopwords_and_punctuation(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        [milk, milk.zip]\n",
       "1       [roses, red, violets, blue, n't, say, yes, 'll...\n",
       "2       [breaking, news, russia, releases, photo, dona...\n",
       "3                        [man, seeking, woman, ignad, 18]\n",
       "4       [explaining, deep, lore, j.r.r, tolkein, 's, w...\n",
       "                              ...                        \n",
       "9995                                [waiting, end, covid]\n",
       "9996                               [smart, women, around]\n",
       "9997                        [good, girls, behind, corner]\n",
       "9998                                      [cooking, wife]\n",
       "9999                           [listen, tomorrow, monday]\n",
       "Name: Text Transcription, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(tokens_list: pd.Series) -> pd.Series:\n",
    "    return tokens_list.explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocabulary)=21255\n"
     ]
    }
   ],
   "source": [
    "vocabulary = get_vocabulary(tokens_list)\n",
    "print(f'{len(vocabulary)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove words with occurence less than k from vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_with_removed_less_than_k(vocabulary, k):\n",
    "    return vocabulary[vocabulary > k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_voc = vocabulary_with_removed_less_than_k(vocabulary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s          1820\n",
       "n't         1416\n",
       "women       1208\n",
       "like         863\n",
       "woman        682\n",
       "            ... \n",
       "asses         11\n",
       "metoo         11\n",
       "buying        11\n",
       "radio         11\n",
       "prepared      11\n",
       "Name: Text Transcription, Length: 1648, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(smaller_voc)=1648\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(smaller_voc)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load glove weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_weights = load_embedding_weights(\n",
    "    vocabulary=smaller_voc,\n",
    "    embedding_size=50,\n",
    "    embedding_type='glove',\n",
    "    path='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(glove_weights)=1648\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(glove_weights)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens_list(tokens_list):\n",
    "    lemmatized_tokens_list = []\n",
    "    for pos_tags in pos_tag_sents(tokens_list):\n",
    "        lemmatized_tokens_list.append([\n",
    "            lemmatizer.lemmatize(token, pos=get_wordnet_pos(pos))\n",
    "            for token, pos in pos_tags\n",
    "        ])\n",
    "    return pd.Series(lemmatized_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens_list = lemmatize_tokens_list(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = Word2Vec(lemmatized_tokens_list, vector_size=50, min_count=1, window=5, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_weights = []\n",
    "for word in smaller_voc:\n",
    "    if word in model_word2vec.wv:\n",
    "        word2vec_weights.append(model_word2vec.wv[word])\n",
    "    else:\n",
    "        word2vec_weights.append(word, np.zeros(50))\n",
    "word2vec_weights = np.array(word2vec_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.50008826e-02,  3.97121124e-02,  9.69190383e-04, ...,\n",
       "        -1.16943054e-01,  1.02244392e-01,  8.00101161e-02],\n",
       "       [-4.31099860e-03,  6.21587299e-02,  3.89502011e-03, ...,\n",
       "        -1.21534474e-01,  1.27641901e-01,  8.40811729e-02],\n",
       "       [-2.29673255e-02,  3.76213565e-02,  3.08051128e-02, ...,\n",
       "        -1.61225051e-01,  1.38468012e-01,  7.68636689e-02],\n",
       "       ...,\n",
       "       [-9.72770974e-02,  4.30889875e-01,  2.32173368e-01, ...,\n",
       "        -1.20196009e+00,  1.21108460e+00,  7.28609204e-01],\n",
       "       [-9.72770974e-02,  4.30889875e-01,  2.32173368e-01, ...,\n",
       "        -1.20196009e+00,  1.21108460e+00,  7.28609204e-01],\n",
       "       [-9.72770974e-02,  4.30889875e-01,  2.32173368e-01, ...,\n",
       "        -1.20196009e+00,  1.21108460e+00,  7.28609204e-01]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = int(X['Text Transcription'].map(len).mean())\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(smaller_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X['Text Transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X['Text Transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0, 1016, 1016],\n",
       "       [   0,    0,    0, ...,    3,   87,    7],\n",
       "       [   0,    0,    0, ...,  300,  112,  296],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    1,   32,    7],\n",
       "       [   0,    0,    0, ...,   44,   32,    7],\n",
       "       [   0,    0,    0, ...,   61, 1191,    7]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences = pad_sequences(sequences, input_dim)\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, Y['misogynous'].astype(int), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(smaller_voc), output_dim=len(glove_weights[0]), weights=[glove_weights]))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score(1)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          82400     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               91648     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,177\n",
      "Trainable params: 174,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 15s 47ms/step - loss: 0.5841 - accuracy: 0.6908 - precision: 0.7045 - recall: 0.6562 - f1_score: 0.6662\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 12s 49ms/step - loss: 0.4405 - accuracy: 0.7987 - precision: 0.8067 - recall: 0.7853 - f1_score: 0.6662\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3258 - accuracy: 0.8626 - precision: 0.8690 - recall: 0.8536 - f1_score: 0.6662\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2362 - accuracy: 0.9034 - precision: 0.9087 - recall: 0.8966 - f1_score: 0.6662\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1725 - accuracy: 0.9330 - precision: 0.9329 - recall: 0.9329 - f1_score: 0.6662\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1381 - accuracy: 0.9477 - precision: 0.9502 - recall: 0.9449 - f1_score: 0.6662\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.1337 - accuracy: 0.9509 - precision: 0.9500 - recall: 0.9517 - f1_score: 0.6662\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.1468 - accuracy: 0.9442 - precision: 0.9435 - recall: 0.9449 - f1_score: 0.6662\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.1594 - accuracy: 0.9360 - precision: 0.9377 - recall: 0.9339 - f1_score: 0.6662\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.1605 - accuracy: 0.9359 - precision: 0.9355 - recall: 0.9362 - f1_score: 0.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276d6b02310>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 18ms/step - loss: 0.8881 - accuracy: 0.7435 - precision: 0.7603 - recall: 0.7141 - f1_score: 0.6684\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1 = model.evaluate(X_test, y_test)\n",
    "metrics_list.append(\n",
    "    {\n",
    "        'weights': 'glove',\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(smaller_voc), output_dim=50))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score(1)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          82400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               91648     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,177\n",
      "Trainable params: 174,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 12s 41ms/step - loss: 0.5756 - accuracy: 0.7040 - precision_1: 0.7178 - recall_1: 0.6714 - f1_score: 0.6662\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.4347 - accuracy: 0.8054 - precision_1: 0.8096 - recall_1: 0.7980 - f1_score: 0.6662\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.3651 - accuracy: 0.8400 - precision_1: 0.8440 - recall_1: 0.8338 - f1_score: 0.6662\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.3128 - accuracy: 0.8636 - precision_1: 0.8678 - recall_1: 0.8576 - f1_score: 0.6662\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.2661 - accuracy: 0.8850 - precision_1: 0.8917 - recall_1: 0.8761 - f1_score: 0.6662\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.2368 - accuracy: 0.8992 - precision_1: 0.9100 - recall_1: 0.8859 - f1_score: 0.6662\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.1874 - accuracy: 0.9194 - precision_1: 0.9226 - recall_1: 0.9154 - f1_score: 0.6662\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.1571 - accuracy: 0.9311 - precision_1: 0.9344 - recall_1: 0.9272 - f1_score: 0.6662\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.1359 - accuracy: 0.9464 - precision_1: 0.9503 - recall_1: 0.9419 - f1_score: 0.6662\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.1086 - accuracy: 0.9550 - precision_1: 0.9582 - recall_1: 0.9515 - f1_score: 0.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276dd39ae80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 19ms/step - loss: 1.1260 - accuracy: 0.7265 - precision_1: 0.7265 - recall_1: 0.7301 - f1_score: 0.6684\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1 = model.evaluate(X_test, y_test)\n",
    "metrics_list.append(\n",
    "    {\n",
    "        'weights': 'no weights',\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(smaller_voc), output_dim=len(word2vec_weights[0]), weights=[word2vec_weights]))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score(1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 50)          82400     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               91648     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,177\n",
      "Trainable params: 174,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 13s 44ms/step - loss: 0.6248 - accuracy: 0.6323 - precision_2: 0.6548 - recall_2: 0.5578 - f1_score: 0.6662\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.4576 - accuracy: 0.7900 - precision_2: 0.7956 - recall_2: 0.7800 - f1_score: 0.6662\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.3872 - accuracy: 0.8329 - precision_2: 0.8328 - recall_2: 0.8326 - f1_score: 0.6662\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.3421 - accuracy: 0.8544 - precision_2: 0.8556 - recall_2: 0.8524 - f1_score: 0.6662\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.3109 - accuracy: 0.8741 - precision_2: 0.8724 - recall_2: 0.8761 - f1_score: 0.6662\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.2751 - accuracy: 0.8900 - precision_2: 0.8885 - recall_2: 0.8916 - f1_score: 0.6662\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.2522 - accuracy: 0.9014 - precision_2: 0.8978 - recall_2: 0.9057 - f1_score: 0.6662\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.2176 - accuracy: 0.9164 - precision_2: 0.9112 - recall_2: 0.9224 - f1_score: 0.6662\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.1993 - accuracy: 0.9226 - precision_2: 0.9185 - recall_2: 0.9274 - f1_score: 0.6662\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.1778 - accuracy: 0.9321 - precision_2: 0.9302 - recall_2: 0.9342 - f1_score: 0.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276e17fd250>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 18ms/step - loss: 0.7901 - accuracy: 0.7540 - precision_2: 0.7550 - recall_2: 0.7550 - f1_score: 0.6684\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1 = model.evaluate(X_test, y_test)\n",
    "metrics_list.append(\n",
    "    {\n",
    "        'weights': 'word2vec',\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glove</td>\n",
       "      <td>0.888117</td>\n",
       "      <td>0.7435</td>\n",
       "      <td>0.760339</td>\n",
       "      <td>0.714143</td>\n",
       "      <td>[0.6684421]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no weights</td>\n",
       "      <td>1.126034</td>\n",
       "      <td>0.7265</td>\n",
       "      <td>0.726462</td>\n",
       "      <td>0.730080</td>\n",
       "      <td>[0.6684421]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.790129</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.754980</td>\n",
       "      <td>0.754980</td>\n",
       "      <td>[0.6684421]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weights      loss  accuracy  precision    recall           f1\n",
       "0       glove  0.888117    0.7435   0.760339  0.714143  [0.6684421]\n",
       "1  no weights  1.126034    0.7265   0.726462  0.730080  [0.6684421]\n",
       "2    word2vec  0.790129    0.7540   0.754980  0.754980  [0.6684421]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the highest accuracy with the word2vec weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For problem 2 we need to change Y to have 4 classes. Change the last layer to be 4 sigmoids, 1 for each class.\n",
    "And change the F1 score to be 4 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    padded_sequences, Y[['shaming', 'stereotype', 'objectification', 'violence']].astype(int), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(smaller_voc), output_dim=len(glove_weights[0]), weights=[glove_weights]))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score(4)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 50)          82400     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               91648     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,564\n",
      "Trainable params: 174,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 13s 41ms/step - loss: 0.4342 - accuracy: 0.2141 - precision_3: 0.5437 - recall_3: 0.0933 - f1_score: 0.1964\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.3689 - accuracy: 0.2637 - precision_3: 0.6486 - recall_3: 0.2954 - f1_score: 0.2670\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.3261 - accuracy: 0.2946 - precision_3: 0.6830 - recall_3: 0.4190 - f1_score: 0.3372\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.2788 - accuracy: 0.3430 - precision_3: 0.7450 - recall_3: 0.5311 - f1_score: 0.4119\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.2303 - accuracy: 0.3676 - precision_3: 0.7972 - recall_3: 0.6311 - f1_score: 0.4537\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.1882 - accuracy: 0.3913 - precision_3: 0.8409 - recall_3: 0.7200 - f1_score: 0.4797\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.1641 - accuracy: 0.4021 - precision_3: 0.8557 - recall_3: 0.7569 - f1_score: 0.4932\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.1461 - accuracy: 0.4252 - precision_3: 0.8675 - recall_3: 0.7984 - f1_score: 0.4986\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.1272 - accuracy: 0.4428 - precision_3: 0.8904 - recall_3: 0.8310 - f1_score: 0.5048\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.1097 - accuracy: 0.4408 - precision_3: 0.9070 - recall_3: 0.8562 - f1_score: 0.5102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276e72d6610>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 18ms/step - loss: 0.7146 - accuracy: 0.2970 - precision_3: 0.4605 - recall_3: 0.4049 - f1_score: 0.3164\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1 = model.evaluate(X_test, Y_test)\n",
    "metrics_list.append(\n",
    "    {\n",
    "        'weights': 'glove',\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(smaller_voc), output_dim=50))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score(4)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 50)          82400     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 128)               91648     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,564\n",
      "Trainable params: 174,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 13s 42ms/step - loss: 0.4322 - accuracy: 0.2061 - precision_4: 0.5568 - recall_4: 0.0929 - f1_score: 0.1739\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.3630 - accuracy: 0.2553 - precision_4: 0.6467 - recall_4: 0.3109 - f1_score: 0.2749\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.3205 - accuracy: 0.3000 - precision_4: 0.7059 - recall_4: 0.4197 - f1_score: 0.3629\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 11s 44ms/step - loss: 0.2866 - accuracy: 0.3350 - precision_4: 0.7284 - recall_4: 0.5027 - f1_score: 0.4082\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.2538 - accuracy: 0.3540 - precision_4: 0.7576 - recall_4: 0.5685 - f1_score: 0.4395\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.2253 - accuracy: 0.3791 - precision_4: 0.7919 - recall_4: 0.6301 - f1_score: 0.4574\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.1970 - accuracy: 0.3900 - precision_4: 0.8176 - recall_4: 0.6951 - f1_score: 0.4636\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.1705 - accuracy: 0.3997 - precision_4: 0.8443 - recall_4: 0.7405 - f1_score: 0.4888\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.1491 - accuracy: 0.4006 - precision_4: 0.8617 - recall_4: 0.7889 - f1_score: 0.4991\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 11s 42ms/step - loss: 0.1317 - accuracy: 0.4087 - precision_4: 0.8800 - recall_4: 0.8169 - f1_score: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276ea3124f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 18ms/step - loss: 0.7066 - accuracy: 0.3000 - precision_4: 0.4816 - recall_4: 0.4181 - f1_score: 0.3581\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1 = model.evaluate(X_test, Y_test)\n",
    "metrics_list.append(\n",
    "    {\n",
    "        'weights': 'no weights',\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(smaller_voc), output_dim=len(word2vec_weights[0]), weights=[word2vec_weights]))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), F1Score(4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 50)          82400     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               91648     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,564\n",
      "Trainable params: 174,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 13s 40ms/step - loss: 0.4508 - accuracy: 0.1972 - precision_5: 0.3897 - recall_5: 0.0131 - f1_score: 0.1551\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.4271 - accuracy: 0.2119 - precision_5: 0.5604 - recall_5: 0.0800 - f1_score: 0.1897\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.4017 - accuracy: 0.2490 - precision_5: 0.6094 - recall_5: 0.1749 - f1_score: 0.2238\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3758 - accuracy: 0.3139 - precision_5: 0.6581 - recall_5: 0.2645 - f1_score: 0.2736\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3578 - accuracy: 0.3474 - precision_5: 0.6591 - recall_5: 0.3094 - f1_score: 0.2943\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3407 - accuracy: 0.3405 - precision_5: 0.6788 - recall_5: 0.3502 - f1_score: 0.3169\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.3247 - accuracy: 0.3610 - precision_5: 0.6892 - recall_5: 0.3935 - f1_score: 0.3413\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 11s 43ms/step - loss: 0.3084 - accuracy: 0.3562 - precision_5: 0.6947 - recall_5: 0.4378 - f1_score: 0.3531\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 11s 46ms/step - loss: 0.2942 - accuracy: 0.3663 - precision_5: 0.7065 - recall_5: 0.4737 - f1_score: 0.3615\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 0.2831 - accuracy: 0.3784 - precision_5: 0.7132 - recall_5: 0.5180 - f1_score: 0.3709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276efab57f0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 20ms/step - loss: 0.5199 - accuracy: 0.3370 - precision_5: 0.4759 - recall_5: 0.3021 - f1_score: 0.2968\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1 = model.evaluate(X_test, Y_test)\n",
    "metrics_list.append(\n",
    "    {\n",
    "        'weights': 'word2vec',\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glove</td>\n",
       "      <td>0.714575</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.460506</td>\n",
       "      <td>0.404861</td>\n",
       "      <td>[0.24568139, 0.4531365, 0.3494983, 0.2173913]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no weights</td>\n",
       "      <td>0.706650</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.418056</td>\n",
       "      <td>[0.29038858, 0.4411567, 0.38468552, 0.3160763]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.519872</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.475930</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>[0.17335474, 0.46614397, 0.32258064, 0.22492401]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weights      loss  accuracy  precision    recall  \\\n",
       "0       glove  0.714575     0.297   0.460506  0.404861   \n",
       "1  no weights  0.706650     0.300   0.481600  0.418056   \n",
       "2    word2vec  0.519872     0.337   0.475930  0.302083   \n",
       "\n",
       "                                                 f1  \n",
       "0     [0.24568139, 0.4531365, 0.3494983, 0.2173913]  \n",
       "1    [0.29038858, 0.4411567, 0.38468552, 0.3160763]  \n",
       "2  [0.17335474, 0.46614397, 0.32258064, 0.22492401]  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy wise we got the best result with word2vec. But it seems to have a bad f1 score for shaming."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e80fdab2d3ad9efed371898a93eb8b1ed0f8415180d1e274f951213442b4295"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38_ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
